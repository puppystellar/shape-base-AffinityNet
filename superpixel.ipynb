{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "1.13.1\n",
      "0.14.1\n",
      "None\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)\n",
    "\n",
    "print(torchvision.__version__)\n",
    "print(torch.version.cuda)\n",
    "\n",
    "a = torch.Tensor(3, 5)\n",
    "# a = a.cuda()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import os\n",
    "import cv2\n",
    "import torch.backends.cudnn as cudnn\n",
    "# import models\n",
    "import torchvision.transforms as transforms\n",
    "# import flow_transforms\n",
    "from imageio import imread\n",
    "from imageio import imsave\n",
    "\n",
    "# from loss import *\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch SPixelNet inference on a folder of imgs',\n",
    "                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "\n",
    "parser.add_argument('--data_dir', metavar='DIR', default='./demo/inputs', help='path to images folder')\n",
    "parser.add_argument('--data_suffix',  default='jpg', help='suffix of the testing image')\n",
    "\n",
    "parser.add_argument('--pretrained', metavar='PTH', help='path to pre-trained model',\n",
    "                                    default= './pretrain_ckpt/SpixelNet_bsd_ckpt.tar')\n",
    "\n",
    "parser.add_argument('--output', metavar='DIR', default= './demo' , help='path to output folder')\n",
    "\n",
    "parser.add_argument('--downsize', default=4, type=float,help='superpixel grid cell, must be same as training setting')\n",
    "\n",
    "parser.add_argument('--num_threads', default=1, type=int,  help='num_threads')\n",
    "parser.add_argument('--batch-size', default=1, type=int, metavar='N', help='mini-batch size')\n",
    "args = parser.parse_args(args=['--data_dir','./demo/inputs','--data_suffix','jpg','--pretrained', \n",
    "           './pretrain_ckpt/SpixelNet_bsd_ckpt.tar','--output', './demo','--downsize','4',\n",
    "           '--num_threads', '1', '--batch-size', '1'])\n",
    "print(args)\n",
    "random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArrayToTensor(object):\n",
    "    \"\"\"Converts a numpy.ndarray (H x W x C) to a torch.FloatTensor of shape (C x H x W).\"\"\"\n",
    "\n",
    "    def __call__(self, array):\n",
    "        assert(isinstance(array, np.ndarray))\n",
    "\n",
    "        array = np.transpose(array, (2, 0, 1))\n",
    "        # handle numpy array\n",
    "        tensor = torch.from_numpy(array)\n",
    "        # put it from HWC to CHW format\n",
    "\n",
    "        return tensor.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "input_transform = transforms.Compose([\n",
    "        ArrayToTensor(),\n",
    "        transforms.Normalize(mean=[0,0,0], std=[255,255,255]),\n",
    "        transforms.Normalize(mean=[0.411,0.432,0.45], std=[1,1,1])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jq/6hj2w9vj1ls5bq_d12lzcyjw0000gn/T/ipykernel_42487/999723470.py:2: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img_ = imread(load_path)[:, :, :3]\n"
     ]
    }
   ],
   "source": [
    "load_path = 'img/Lena.jpg'\n",
    "img_ = imread(load_path)[:, :, :3]\n",
    "# print(img_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift9pos(input, h_shift_unit=1,  w_shift_unit=1):\n",
    "    # input should be padding as (c, 1+ height+1, 1+width+1)\n",
    "    input_pd = np.pad(input, ((h_shift_unit, h_shift_unit), (w_shift_unit, w_shift_unit)), mode='edge')\n",
    "    input_pd = np.expand_dims(input_pd, axis=0)\n",
    "\n",
    "    # assign to ...\n",
    "    top     = input_pd[:, :-2 * h_shift_unit,          w_shift_unit:-w_shift_unit]\n",
    "    bottom  = input_pd[:, 2 * h_shift_unit:,           w_shift_unit:-w_shift_unit]\n",
    "    left    = input_pd[:, h_shift_unit:-h_shift_unit,  :-2 * w_shift_unit]\n",
    "    right   = input_pd[:, h_shift_unit:-h_shift_unit,  2 * w_shift_unit:]\n",
    "\n",
    "    center = input_pd[:,h_shift_unit:-h_shift_unit,w_shift_unit:-w_shift_unit]\n",
    "\n",
    "    bottom_right    = input_pd[:, 2 * h_shift_unit:,   2 * w_shift_unit:]\n",
    "    bottom_left     = input_pd[:, 2 * h_shift_unit:,   :-2 * w_shift_unit]\n",
    "    top_right       = input_pd[:, :-2 * h_shift_unit,  2 * w_shift_unit:]\n",
    "    top_left        = input_pd[:, :-2 * h_shift_unit,  :-2 * w_shift_unit]\n",
    "\n",
    "    shift_tensor = np.concatenate([     top_left,    top,      top_right,\n",
    "                                        left,        center,      right,\n",
    "                                        bottom_left, bottom,    bottom_right], axis=0)\n",
    "    return shift_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W, _ = img_.shape\n",
    "# ceil向上取整\n",
    "# H_, W_  = int(np.ceil(H/16.)*16), int(np.ceil(W/16.)*16)\n",
    "H_, W_  = int(np.ceil(H/4.)*4), int(np.ceil(W/4.)*4)\n",
    "n_spixl_h = int(np.floor(H_ / args.downsize))\n",
    "n_spixl_w = int(np.floor(W_ / args.downsize))\n",
    "print(H_, W_) # 32*32\n",
    "print('downsize=', args.downsize) # downsize=4.0\n",
    "print('spixl-h', n_spixl_h) # superpixel-h=8\n",
    "print('spixl-w', n_spixl_w) # superpixel-w=8\n",
    "\n",
    "spix_values = np.int32(np.arange(0, n_spixl_w * n_spixl_h).reshape((n_spixl_h, n_spixl_w)))\n",
    "spix_idx_tensor_ = shift9pos(spix_values)\n",
    "print('spixel_values', spix_values.shape, '\\n', spix_values) # shape=8*8\n",
    "print('after shifting position')\n",
    "print('spixel_idx_tensor',spix_idx_tensor_.shape, '\\n', spix_idx_tensor_) # tensor shape=(9,8,8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在宽度和高度维上进行复制，downsize是下采样倍数\n",
    "spix_idx_tensor = np.repeat(\n",
    "      np.repeat(spix_idx_tensor_, args.downsize, axis=1), args.downsize, axis=2)\n",
    "print('spix_idx_tensor_', spix_idx_tensor_.shape, '\\n', spix_idx_tensor_)\n",
    "# 9，H/downsize，W/downsize\n",
    "# 9， 2H/downsize，2W/downsize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超像素个数\n",
    "n_spixel =  int(n_spixl_h * n_spixl_w)\n",
    "# 扩张成4dim tensor，分别是pic数量1，超像素索引，高度，宽度\n",
    "spixeIds = torch.from_numpy(np.tile(spix_idx_tensor, (1, 1, 1, 1))).type(torch.float).cuda()\n",
    "# from_numpy 将数组变成tensor并且改变tensor的值，array值也会变\n",
    "print('n_spixel', n_spixel) \n",
    "# n_pixel = 64\n",
    "print('spixeIds', spixeIds.shape, '\\n', spixeIds)\n",
    "#  torchsize=([1, 9, 32, 32])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating superpixel index\n",
    "\n",
    "def update_spixl_map (spixl_map_idx_in, assig_map_in):\n",
    "    assig_map = assig_map_in.clone()\n",
    "\n",
    "    b,_,h,w = assig_map.shape\n",
    "    _, _, id_h, id_w = spixl_map_idx_in.shape\n",
    "\n",
    "    print('output',h, w )\n",
    "    print('spixl', id_h, id_w)\n",
    "    # 当前像素位置hw与给定的超像素索引，相同将super pixel index赋值给map idx\n",
    "    if (id_h == h) and (id_w == w):\n",
    "        spixl_map_idx = spixl_map_idx_in\n",
    "    else:\n",
    "        # 不同需要上采样or下采样调整为in\n",
    "        spixl_map_idx = F.interpolate(spixl_map_idx_in, size=(h,w), mode='nearest')\n",
    "    # 计算分配概率assign map中超像素最大概率作为该超像素的超像素标签\n",
    "    assig_max,_ = torch.max(assig_map, dim=1, keepdim= True)\n",
    "    # 属于标签的设1，否则0\n",
    "    assignment_ = torch.where(assig_map == assig_max, torch.ones(assig_map.shape).cuda(),torch.zeros(assig_map.shape).cuda())\n",
    "    # 更新超像素标签\n",
    "    new_spixl_map_ = spixl_map_idx * assignment_ # winner take all\n",
    "    # new_spixl_map = torch.sum(new_spixl_map_,dim=1,keepdim=True).type(torch.int)\n",
    "\n",
    "    return new_spixl_map_, assignment_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function： 得到超像素分割图，以及进行enforce connect约束后超像素索引\n",
    "\n",
    "def get_spixel_image(given_img, spix_index, n_spixels = 600, b_enforce_connect = False):\n",
    "    # enforce_connectivity如果设置成truth能够减少生成的数量，结合更紧密\n",
    "    if not isinstance(given_img, np.ndarray):\n",
    "        given_img_np_ = given_img.detach().cpu().numpy().transpose(1,2,0)\n",
    "    else: # for cvt lab to rgb case\n",
    "        given_img_np_ = given_img\n",
    "\n",
    "    if not isinstance(spix_index, np.ndarray):\n",
    "        spix_index_np = spix_index.detach().cpu().numpy().transpose(0,1)\n",
    "    else:\n",
    "        spix_index_np = spix_index\n",
    "\n",
    "    h, w = spix_index_np.shape\n",
    "    given_img_np = cv2.resize(given_img_np_, dsize=(w, h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    if b_enforce_connect:\n",
    "        spix_index_np = spix_index_np.astype(np.int64)\n",
    "        segment_size = (given_img_np_.shape[0] * given_img_np_.shape[1]) / (int(n_spixels) * 1.0)\n",
    "        min_size = int(0.06 * segment_size)\n",
    "        max_size =  int(3 * segment_size)\n",
    "        # index包含所有像素所属的超像素的索引，min和max是限制超像素最大最小尺寸参数\n",
    "        spix_index_np = enforce_connectivity(spix_index_np[None, :, :], min_size, max_size)[0]\n",
    "    cur_max = np.max(given_img_np)\n",
    "    # 先/curmax像素归一化，超像素index转化为int类型，边缘颜色定为青色011\n",
    "    spixel_bd_image = mark_boundaries(given_img_np/cur_max, spix_index_np.astype(int), color = (0,1,1)) #cyna\n",
    "    return (cur_max*spixel_bd_image).astype(np.float32).transpose(2,0,1), spix_index_np #\n",
    "    # 返回超像素边界图，以及index用于后续任务中使用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from connectivity import enforce_connectivity\n",
    "from skimage.segmentation import mark_boundaries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.resize(img_, (W_, H_), interpolation=cv2.INTER_CUBIC)\n",
    "# normalization\n",
    "img1 = input_transform(img)\n",
    "ori_img = input_transform(img_)\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "print('input_transform img', img1.shape, '\\n') # 3*32*32\n",
    "\n",
    "# tensor[3，16，16]\n",
    "\n",
    "# output = model(img1.cuda().unsqueeze(0))\n",
    "# unsqueeze(0)将数据扩充维度，理解为给数据的索引，方便网络对数据进行批处理batch\n",
    "# output tensor [1,9,16,16]\n",
    "\n",
    "output = torch.load('2_32_4.pt')\n",
    "# assign the spixel map\n",
    "print('spixeIds', spixeIds.shape) # 1*9*32*32\n",
    "print('output', output.shape) # 1*9*32*32\n",
    "curr_spixl_map, assignment_ = update_spixl_map(spixeIds, output)\n",
    "# ori_sz_spixel_map = F.interpolate(curr_spixl_map.type(torch.float), size=( H_,W_), mode='nearest').type(torch.int)\n",
    "# 如果size合规的话curr_spixel_map就等于ori_sz_spixel_map\n",
    "mean_values = torch.tensor([0.411, 0.432, 0.45], dtype=img1.cuda().unsqueeze(0).dtype).view(3, 1, 1)\n",
    "print('mean_values', mean_values.shape, '\\n', mean_values) # 3*1*1\n",
    "\n",
    "# get_spixel_image参数分别是\n",
    "# spixel_viz, spixel_label_map = get_spixel_image((ori_img + mean_values).clamp(0, 1), curr_spixl_map.squeeze(), n_spixels= n_spixel,  b_enforce_connect=True)\n",
    "\n",
    "# clamp将输入的normalization的tensor压缩到0-1之间，输出一个新的tensor\n",
    "# squeeze 将维度为1的删除\n",
    "\n",
    "\n",
    "print('assignment', assignment_.shape)\n",
    "# shape: 1,9,32,32\n",
    "# 将assignment可视化steps：1.压缩维度，2.选取需要维度，3.转化为数组，4.可视化\n",
    "assignment = torch.squeeze(assignment_)\n",
    "# squeeze去掉一维\n",
    "# shape: 9,32,32\n",
    "# assignment = torch.sum(assignment_,dim=0,keepdim=True).type(torch.int)\n",
    "'''\n",
    "indices = torch.tensor([0])\n",
    "torch.index_select(assignment, 0, indices)\n",
    "'''\n",
    "for i in range(0, 1):\n",
    "    assignment = assignment[i,:,:]\n",
    "    assignment = assignment.cpu().numpy()\n",
    "    # plt.matshow(assignment, cmap=plt.cm.Blues)\n",
    "    ax = plt.matshow(assignment)\n",
    "    plt.colorbar(ax.colorbar)\n",
    "    plt.title(\"assignment map\")\n",
    "    plt.show()\n",
    "\n",
    "# print('curr_spixl_map', curr_spixl_map.shape, '\\n', curr_spixl_map)\n",
    "\n",
    "curr_spixl_map = torch.squeeze(curr_spixl_map)\n",
    "curr_spixl_map = curr_spixl_map[0,:,:]\n",
    "print('curr_spixl_map shape', curr_spixl_map.shape)\n",
    "curr_spixl_map = curr_spixl_map.cpu().numpy()\n",
    "# plt.matshow(assignment, cmap=plt.cm.Blues)\n",
    "ax = plt.matshow(curr_spixl_map)\n",
    "plt.colorbar(ax.colorbar)\n",
    "plt.title(\"cur_spixl map\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('assignment', assignment_.shape, '\\n', assignment_)\n",
    "\n",
    "print('get final spixel map')\n",
    "# print('spixel_viz', spixel_viz.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('py37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "324d8a55dc267c50f0ea1e187931266d020772f5af4cf5c73e2fa7e7e3a2306a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
